{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35ccd44",
   "metadata": {},
   "source": [
    "# **Modeling**\n",
    "\n",
    "### 1. Tổng quan & Chiến lược tiếp cận\n",
    "\n",
    "Sau khi hoàn tất quá trình Khám phá dữ liệu (EDA) và Tiền xử lý (Preprocessing), chúng ta đã có một bộ dữ liệu sạch, được mã hóa và bổ sung các đặc trưng tương tác mạnh mẽ (như `is_startup_veteran`, `brain_drain_risk`...).\n",
    "\n",
    "Mục tiêu của chương này là xây dựng các mô hình Máy học (Machine Learning) để giải quyết bài toán **Phân loại nhị phân (Binary Classification)**: Dự đoán xác suất một ứng viên sẽ thay đổi công việc (`target = 1`) hay ở lại (`target = 0`).\n",
    "\n",
    "Chiến lược Modeling được thực hiện theo nguyên tắc **\"Từ đơn giản đến phức tạp\"**, bao gồm 3 giai đoạn:\n",
    "\n",
    "1.  **Thiết lập Baseline (Mô hình cơ sở):** Sử dụng **Logistic Regression** để đánh giá hiệu quả của các biến đầu vào và thiết lập mức chuẩn so sánh.\n",
    "2.  **Thử nghiệm mô hình phi tuyến:** Sử dụng **Random Forest** \n",
    "3.  **Tối ưu hóa với mô hình phi tuyến:** Sử dụng **XGBoost** để nắm bắt các mối quan hệ phức tạp và các điểm gãy (splits) mà hai mô hình trên có thể bỏ sót.\n",
    "\n",
    "### 2. Tiêu chí đánh giá (Evaluation Metrics)\n",
    "\n",
    "Do bộ dữ liệu có sự mất cân bằng nhẹ (tỷ lệ `target=1` chiếm ~25%), việc chỉ sử dụng độ chính xác (**Accuracy**) có thể gây hiểu nhầm. Chúng ta sẽ tập trung vào các chỉ số sau:\n",
    "\n",
    "* **Recall:** Đây là chỉ số quan trọng nhất về mặt quản trị rủi ro. Chúng ta muốn mô hình \"bắt\" được tối đa những người có ý định nghỉ việc để HR kịp thời can thiệp.\n",
    "* **F1-Score:** Thước đo hài hòa giữa Precision và Recall, giúp đánh giá tổng quát hiệu năng của mô hình trên nhóm thiểu số.\n",
    "* **ROC-AUC:** Đánh giá khả năng phân loại của mô hình ở các ngưỡng (threshold) khác nhau.\n",
    "\n",
    "### 3. Quy trình Huấn luyện (Training Pipeline)\n",
    "\n",
    "Quá trình huấn luyện sẽ tuân thủ các bước:\n",
    "1.  **Chia tập dữ liệu (Train-Test Split):** Tỷ lệ 80% Train - 20% Test để đảm bảo mô hình được đánh giá khách quan trên dữ liệu chưa từng thấy.\n",
    "2.  **Tinh chỉnh tham số (Hyperparameter Tuning):** Sử dụng `GridSearchCV` để tìm ra bộ tham số tối ưu nhất cho từng thuật toán (ví dụ: tìm `k` cho KNN, `n_estimators` cho Random Forest).\n",
    "3.  **Phân tích kết quả:** So sánh hiệu năng giữa các mô hình và phân tích lí do nguyên nhân vì sao lại như vậy.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ce117",
   "metadata": {},
   "source": [
    "## **Setup & Import**\n",
    "\n",
    "- Khởi tạo đường dẫn project.\n",
    "- Import các hàm/mô hình đã cài trong `src/`.\n",
    "- Set random seed để kết quả tái lập.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12a59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from src.models import (\n",
    "    load_xy_from_clean_csv,\n",
    "    train_val_test_split,\n",
    "    roc_auc_score,\n",
    "    LogisticRegression,\n",
    "    RandomForest,\n",
    "    XGBoost,\n",
    "    evaluate_binary_classification,\n",
    "    find_best_threshold,\n",
    ")\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "RANDOM_STATE = 23120329\n",
    "THRESHOLD_DEFAULT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547611aa",
   "metadata": {},
   "source": [
    "## **Load & chuẩn bị dữ liệu**\n",
    "\n",
    "- Đọc file CSV đã được xử lý sạch .\n",
    "- Tách `X` (feature) và `y` (target).\n",
    "- Chia dữ liệu: Từ tập dữ liệu sạch ban đầu, ta chia thành 3 phần:\n",
    "    * **Train (~60%):** dùng để cập nhật trọng số mô hình.\n",
    "    * **Validation (~20%):** dùng để:\n",
    "        * Theo dõi val loss trong quá trình training.\n",
    "        * Áp dụng early stopping.\n",
    "        * Chọn threshold tối ưu.\n",
    "    * **Test (~20%):** chỉ sử dụng một lần ở cuối để đánh giá mô hình sau khi mọi quyết định về kiến trúc, hyperparameter và threshold đã được cố định.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a32f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (19158, 28)\n",
      "y shape: (19158,)\n",
      "Số feature: 28\n",
      "Train: (11496, 28)\n",
      "Val  : (3831, 28)\n",
      "Test : (3831, 28)\n"
     ]
    }
   ],
   "source": [
    "CLEAN_CSV_PATH = os.path.join(PROJECT_ROOT, \"data/processed\", \"aug_train.csv\")\n",
    "\n",
    "X, y, feature_names = load_xy_from_clean_csv(CLEAN_CSV_PATH, target_col=\"target\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Số feature:\", len(feature_names))\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val  :\", X_val.shape)\n",
    "print(\"Test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d2863",
   "metadata": {},
   "source": [
    "## **Mô hình 1: Logistic Regression**\n",
    "\n",
    "**Lý do chọn:**\n",
    "* Đây là mô hình chuẩn, đơn giản, dễ diễn giải: mỗi hệ số tương ứng “tác động” của một feature đến log-odds đổi việc.\n",
    "* Logistic Regression thường được dùng làm baseline cho các bài toán churn/attrition, nên rất phù hợp với bài toán HR này.\n",
    "\n",
    "**Thiết lập:**\n",
    "* Dùng phiên bản Logistic Regression tự cài bằng NumPy:\n",
    "    * Mini-batch gradient descent.\n",
    "    * Optimizer Adam.\n",
    "    * Regularization L2 nhỏ để giảm overfitting.\n",
    "* Dữ liệu được chuẩn hóa (standardization) trên train, rồi áp dụng cho val/test.\n",
    "* Trong fit, mỗi epoch:\n",
    "    * Duyệt qua các mini-batch.\n",
    "    * Cập nhật trọng số bằng Adam.\n",
    "* Sau epoch, tính:\n",
    "    * Train loss (binary cross-entropy trên train).\n",
    "    * Val loss (nếu có val).\n",
    "* Thanh tiến trình (`tqdm`) hiển thị epoch hiện tại, train loss và val loss.\n",
    "\n",
    "**Early stopping:**\n",
    "* Dùng val loss làm tiêu chí:\n",
    "    * Nếu val loss không giảm sau `patience` epoch liên tiếp, dừng sớm.\n",
    "    * Giữ lại trọng số tốt nhất quan sát được (best val loss).\n",
    "* Lý do: Logistic là mô hình đơn giản nhưng vẫn có thể overfit nếu số epoch quá lớn, đặc biệt với dữ liệu không cân bằng.\n",
    "\n",
    "**Đánh giá:**\n",
    "* Trên validation:\n",
    "    * Tính accuracy, precision, recall, F1, confusion matrix, roc_auc.\n",
    "    * Threshold mặc định: THRESHOLD_DEFAULT.\n",
    "* Sau khi hài lòng với setting, dùng cùng mô hình và threshold THRESHOLD_DEFAULT để đánh giá trên test.\n",
    "\n",
    "**Vai trò:**\n",
    "Logistic Regression cung cấp một baseline tuyến tính:\n",
    "* Cho thấy mức performance “đơn giản nhất” ta đạt được.\n",
    "* Là mốc để so sánh xem Random Forest và XGBoost có thật sự đem lại lợi ích hay chỉ phức tạp hơn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e674f82",
   "metadata": {},
   "source": [
    "### **Trainning**\n",
    "Đoạn code thực hiện **Grid Search** thủ công để tìm bộ tham số tốt nhất cho mô hình Logistic Regression:\n",
    "\n",
    "1.  **Thiết lập không gian tìm kiếm:**\n",
    "    * `Learning Rate`: [0.01, 0.05]\n",
    "    * `L2 Regularization`: [0.0, 0.001]\n",
    "    * `Batch Size`: [128, 256]\n",
    "\n",
    "2.  **Quy trình thực hiện:**\n",
    "    * Duyệt qua từng tổ hợp tham số.\n",
    "    * Huấn luyện mô hình với cơ chế **Early Stopping** (dừng sớm nếu không cải thiện sau 30 epochs) và tối ưu hóa bằng **Adam**.\n",
    "    * Đánh giá mô hình trên tập **Validation**.\n",
    "\n",
    "3.  **Lựa chọn mô hình:**\n",
    "    * Sử dụng **F1-Score** làm tiêu chí quyết định.\n",
    "    * Lưu lại bộ tham số và mô hình có F1-Score cao nhất trên tập Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181e941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thực hiện Grid Search cho Logistic Regression...\n",
      "\n",
      "[lr=0.01, l2=0.0, batch=128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  54%|█████▍    | 54/100 [00:00<00:00, 162.89it/s, train=0.4609, val=0.4584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 55 | best_loss = 0.4575\n",
      "  F1-score Validation = 0.5929\n",
      "\n",
      "[lr=0.01, l2=0.0, batch=256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  47%|████▋     | 47/100 [00:00<00:00, 198.23it/s, train=0.4612, val=0.4576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 48 | best_loss = 0.4576\n",
      "  F1-score Validation = 0.5923\n",
      "\n",
      "[lr=0.01, l2=0.001, batch=128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  46%|████▌     | 46/100 [00:00<00:00, 161.62it/s, train=0.4640, val=0.4589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 47 | best_loss = 0.4589\n",
      "  F1-score Validation = 0.5869\n",
      "\n",
      "[lr=0.01, l2=0.001, batch=256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  62%|██████▏   | 62/100 [00:00<00:00, 184.18it/s, train=0.4640, val=0.4591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 63 | best_loss = 0.4591\n",
      "  F1-score Validation = 0.5873\n",
      "\n",
      "[lr=0.05, l2=0.0, batch=128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  47%|████▋     | 47/100 [00:00<00:00, 156.10it/s, train=0.4615, val=0.4583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 48 | best_loss = 0.4580\n",
      "  F1-score Validation = 0.5921\n",
      "\n",
      "[lr=0.05, l2=0.0, batch=256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  36%|███▌      | 36/100 [00:00<00:00, 204.06it/s, train=0.4620, val=0.4599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 37 | best_loss = 0.4576\n",
      "  F1-score Validation = 0.5939\n",
      "\n",
      "[lr=0.05, l2=0.001, batch=128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  47%|████▋     | 47/100 [00:00<00:00, 145.17it/s, train=0.4646, val=0.4597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 48 | best_loss = 0.4591\n",
      "  F1-score Validation = 0.5869\n",
      "\n",
      "[lr=0.05, l2=0.001, batch=256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  36%|███▌      | 36/100 [00:00<00:00, 188.23it/s, train=0.4653, val=0.4616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] quá trình huấn luyện dừng lại tại epoch 37 | best_loss = 0.4589\n",
      "  F1-score Validation = 0.5889\n",
      "\n",
      "Bộ tham số tốt nhất:\n",
      "Best learning rate = 0.05\n",
      "Best l2            = 0.0\n",
      "Best batch         = 256\n",
      "Best threshold     = 0.2663\n",
      "\n",
      "Metrics:\n",
      "  Accuracy         : 0.7552\n",
      "  Precision        : 0.4996\n",
      "  Recall           : 0.7321\n",
      "  F1-score         : 0.5939\n",
      "  Threshold        : 0.2663\n",
      "  Confusion Matrix :\n",
      "[[2207  687]\n",
      " [ 251  686]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid search Logistic Regression\n",
    "lr_list = [0.01, 0.05]\n",
    "l2_list = [0.0, 0.001]\n",
    "batch_list = [128, 256]\n",
    "\n",
    "best_logreg = None\n",
    "best_logreg_f1 = -1.0\n",
    "best_params = None\n",
    "best_threshold = None\n",
    "\n",
    "print(\"Thực hiện Grid Search cho Logistic Regression...\\n\")\n",
    "\n",
    "for lr_ in lr_list:\n",
    "    for l2_ in l2_list:\n",
    "        for batch_ in batch_list:\n",
    "            print(f\"[lr={lr_}, l2={l2_}, batch={batch_}]\")\n",
    "            \n",
    "            model = LogisticRegression(\n",
    "                lr=lr_, \n",
    "                n_epochs=100, \n",
    "                batch_size=batch_, \n",
    "                l2=l2_, \n",
    "                l1=0.0, \n",
    "                optimizer=\"adam\", \n",
    "                lr_decay=1e-3, \n",
    "                early_stopping=True, \n",
    "                patience=30, \n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "            \n",
    "            y_val_prob_tmp = model.predict_proba(X_val)\n",
    "\n",
    "            t_tmp, f1_tmp = find_best_threshold(y_val, y_val_prob_tmp, n_points=200)\n",
    "\n",
    "            metrics_tmp = evaluate_binary_classification(\n",
    "                y_true=y_val,\n",
    "                y_prob=y_val_prob_tmp,\n",
    "                threshold=t_tmp\n",
    "            )\n",
    "\n",
    "            print(f\"  F1-score Validation = {metrics_tmp['f1']:.4f}\\n\")\n",
    "            \n",
    "            if metrics_tmp[\"f1\"] > best_logreg_f1:\n",
    "                best_logreg = model\n",
    "                best_logreg_f1 = metrics_tmp[\"f1\"]\n",
    "                best_params = (lr_, l2_, batch_, metrics_tmp)\n",
    "                best_threshold = t_tmp   \n",
    "\n",
    "m = best_params[3]\n",
    "\n",
    "print(\"Bộ tham số tốt nhất:\")\n",
    "print(f\"Best learning rate = {best_params[0]}\")\n",
    "print(f\"Best l2            = {best_params[1]}\")\n",
    "print(f\"Best batch         = {best_params[2]}\")\n",
    "print(f\"Best threshold     = {best_threshold:.4f}\")\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  Accuracy         : {m['accuracy']:.4f}\")\n",
    "print(f\"  Precision        : {m['precision']:.4f}\")\n",
    "print(f\"  Recall           : {m['recall']:.4f}\")\n",
    "print(f\"  F1-score         : {m['f1']:.4f}\")\n",
    "print(f\"  Threshold        : {best_threshold:.4f}\")  \n",
    "print(f\"  Confusion Matrix :\\n{m['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980f4dc",
   "metadata": {},
   "source": [
    "#### **Nhận xét quá trình huấn luyện Logistic Regression**\n",
    "\n",
    "**1. Khả năng hội tụ & Ổn định:**\n",
    "\n",
    "Trong quá trình Grid Search, Logistic Regression thể hiện khả năng hội tụ rất nhanh và ổn định với mọi cấu hình:\n",
    "* **Early Stopping hiệu quả:** Tất cả các mô hình đều dừng sớm sau khoảng **35–60 epoch**.\n",
    "* **Không Overfitting:** Loss giảm đều đặn, chứng tỏ mô hình học tốt mà không bị khớp quá kỹ vào tập train.\n",
    "* **Độ nhạy:** Mô hình khá bền vững với thay đổi nhỏ của batch size hay learning rate, nhưng phản ứng rõ rệt với Regularization.\n",
    "\n",
    "**2. Về Bộ tham số tối ưu, cấu hình tốt nhất (Best Params):**\n",
    "* **Regularization (L2 = 0.0):** Việc L2 = 0.0 cho kết quả tốt hơn L2 = 0.001 chứng tỏ dữ liệu đã được xử lý tiền kỳ rất tốt (sạch nhiễu, chuẩn hóa, one-hot). Việc thêm Regularization lúc này là không cần thiết và thậm chí làm giảm tính linh hoạt của mô hình.\n",
    "* **Learning Rate (0.05):** Hiệu quả hơn 0.01 nhờ tốc độ cập nhật trọng số nhanh hơn mà vẫn duy trì được sự ổn định.\n",
    "* **Batch Size (256):** Cho kết quả tốt nhất nhờ tạo ra gradient mượt mà và tối ưu hóa ổn định hơn so với các batch nhỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8211050",
   "metadata": {},
   "source": [
    "### **Đánh giá với test set**\n",
    "\n",
    "Quy trình đánh giá được thực hiện theo chiến lược 2 giai đoạn để đảm bảo tính khách quan:\n",
    "\n",
    "1.  **Dự báo xác suất:**\n",
    "    * Tính xác suất (`predict_proba`) cho tập Validation và Test thay vì chỉ dự đoán nhãn cứng (0/1).\n",
    "\n",
    "2.  **Đánh giá hiệu năng (Final Evaluation):**\n",
    "    * Áp dụng ngưỡng tối ưu từ Validation lên tập **Test** (tránh data leakage).\n",
    "    * Xuất các chỉ số quan trọng (Recall, Precision, F1, Confusion Matrix, ROC-AUC) để kết luận năng lực thực tế của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42901826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold Logistic theo F1-score: 0.266\n",
      "\n",
      "============================================================\n",
      "\t   Logistic Regression – Validation vs Test\n",
      "============================================================\n",
      "Metric          | Validation   | Test        \n",
      "------------------------------------------------------------\n",
      "accuracy        |       0.7552 |       0.7648\n",
      "precision       |       0.4996 |       0.5267\n",
      "recall          |       0.7321 |       0.7392\n",
      "f1              |       0.5939 |       0.6151\n",
      "threshold       |       0.2663 |       0.2663\n",
      "roc_auc         |       0.7877 |       0.7954\n",
      "------------------------------------------------------------\n",
      "\n",
      "Confusion matrix (Validation):\n",
      "[[2207  687]\n",
      " [ 251  686]]\n",
      "\n",
      "Confusion matrix (Test):\n",
      "[[2210  647]\n",
      " [ 254  720]]\n"
     ]
    }
   ],
   "source": [
    "y_val_prob_log  = best_logreg.predict_proba(X_val)\n",
    "y_test_prob_log = best_logreg.predict_proba(X_test)\n",
    "\n",
    "best_t_log = best_threshold\n",
    "\n",
    "metrics_log_val  = evaluate_binary_classification(y_val,  y_val_prob_log,  threshold=best_t_log)\n",
    "metrics_log_test = evaluate_binary_classification(y_test, y_test_prob_log, threshold=best_t_log)\n",
    "\n",
    "auc_val_log  = roc_auc_score(y_val,  y_val_prob_log)\n",
    "auc_test_log = roc_auc_score(y_test, y_test_prob_log)\n",
    "\n",
    "print(f\"Best threshold Logistic theo F1-score: {best_t_log:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\t   Logistic Regression – Validation vs Test\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"{'Metric':15s} | {'Validation':12s} | {'Test':12s}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for k in metrics_log_val.keys():\n",
    "    if k == \"confusion_matrix\":\n",
    "        continue\n",
    "    \n",
    "    v_val  = metrics_log_val[k]\n",
    "    v_test = metrics_log_test[k]\n",
    "\n",
    "    if isinstance(v_val, float):\n",
    "        print(f\"{k:15s} | {v_val:12.4f} | {v_test:12.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:15s} | {str(v_val):12s} | {str(v_test):12s}\")\n",
    "\n",
    "print(f\"{'roc_auc':15s} | {auc_val_log:12.4f} | {auc_test_log:12.4f}\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"\\nConfusion matrix (Validation):\")\n",
    "print(metrics_log_val[\"confusion_matrix\"])\n",
    "\n",
    "print(\"\\nConfusion matrix (Test):\")\n",
    "print(metrics_log_test[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128051b7",
   "metadata": {},
   "source": [
    "#### **Nhận xét**\n",
    "\n",
    "Dựa trên kết quả thực nghiệm trên tập Validation và Test, ta có những nhận xét sau về mô hình cơ sở (Baseline):\n",
    "\n",
    "  1. Độ ổn định giữa Validation và Test cho thấy một tín hiệu rất tốt\n",
    "\n",
    "     So sánh hiệu năng giữa hai tập dữ liệu:\n",
    "\n",
    "      | Metric | Val | Test | Nhận xét |\n",
    "      | :--- | :---: | :---: | :--- |\n",
    "      | **Accuracy** | 0.7552 | **0.7648** | Tăng nhẹ  |\n",
    "      | **Precision** | 0.4996 | **0.5267** | Tăng   |\n",
    "      | **Recall** | 0.7321 | **0.7392** | Tăng nhẹ |\n",
    "      | **F1-Score** | 0.5939 | **0.6151** | Tăng   |\n",
    "      | **ROC-AUC** | 0.7877 | **0.7954** | Tăng nhẹ |\n",
    "\n",
    "**Điểm mạnh:** Mô hình không bị **Overfitting**. Hiệu năng trên Test nhỉnh hơn Validation chứng tỏ việc chia dữ liệu hợp lý và mô hình có khả năng tổng quát hóa tốt.\n",
    "\n",
    "  2. Chiến lược \"Thà bắt nhầm còn hơn bỏ sót\"\n",
    "    * **Precision (~0.53):** Dự đoán 100 người nghỉ thì đúng khoảng 53 người.\n",
    "    * **Recall (~0.74):** Bắt được **74%** tổng số người thực sự muốn nghỉ việc.\n",
    "\n",
    "     **Phù hợp đặc thù HR:** Ưu tiên cao nhất là **không bỏ sót** nhân tài có nguy cơ rời đi (High Recall). Tỷ lệ báo động giả cao hơn một chút là chấp nhận được trong bài toán sàng lọc rủi ro.\n",
    "\n",
    "  3. Phân tích Ma trận nhầm lẫn (Confusion Matrix)\n",
    "    Kết quả trên tập Test:\n",
    "     ```text\n",
    "     [[2210  647]\n",
    "     [ 254  720]]\n",
    "     ```\n",
    "     * Điểm sáng (Low False Negative): Chỉ có 254 trường hợp nghỉ việc bị bỏ sót, thấp hơn nhiều so với số lượng 720 trường hợp được phát hiện chính xác (True Positive). Đây là thành công lớn nhất của mô hình trong việc cảnh báo sớm.\n",
    "\n",
    "     * Điểm trừ (High False Positive): Có 647 người bị báo nhầm là nghỉ việc (thực tế ở lại). Điều này gây lãng phí tài nguyên giữ chân, nhưng là sự đánh đổi cần thiết để đạt được Recall cao.\n",
    "\n",
    "**Kết luận:** Logistic Regression là một Baseline mạnh, hoạt động ổn định và hoàn thành tốt nhiệm vụ khoanh vùng nhóm rủi ro cao.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2356a",
   "metadata": {},
   "source": [
    "## **Mô hình 2: Random Forest**\n",
    "\n",
    "**Lý do chọn:**\n",
    "* Quá trình EDA cho thấy mối quan hệ giữa nhiều biến với target không tuyến tính:\n",
    "    * Ví dụ các ngưỡng kinh nghiệm, số năm từ lần đổi việc gần nhất, thời gian training,… thường tạo ra “điểm gãy”.\n",
    "* Random Forest là mô hình tree-based:\n",
    "    * Mỗi cây quyết định (CART) chia dữ liệu theo threshold trên một feature.\n",
    "    * Nhiều cây được train trên các bootstrap sample + random subset feature → giảm variance.\n",
    "\n",
    "**Thiết lập:**\n",
    "* Cài đặt một DecisionTree đơn giản:\n",
    "    * Split theo Gini impurity.\n",
    "    * Dừng theo `max_depth`, `min_samples_split`, node thuần.\n",
    "* RandomForest:\n",
    "    * Số cây `n_estimators` (ví dụ 100).\n",
    "    * `max_depth` để khống chế độ phức tạp mỗi cây.\n",
    "    * `max_features=\"sqrt\"` để mỗi cây chỉ nhìn thấy một phần feature → tăng đa dạng.\n",
    "* Train với progress bar hiển thị quá trình build từng cây.\n",
    "* Khi predict:\n",
    "    * Mỗi cây đưa ra một vote (0/1).\n",
    "    * Xác suất lớp 1 ≈ tỷ lệ số cây vote 1.\n",
    "\n",
    "**Đánh giá:**\n",
    "* Dùng xác suất này để tính metric:\n",
    "    * Validation: tính accuracy, precision, recall, F1 (threshold mặc định 0.5).\n",
    "    * Test: dùng cùng threshold để đánh giá cuối.\n",
    "\n",
    "**Lợi ích & quan sát:**\n",
    "* Random Forest cho phép mô hình “uốn cong” decision boundary:\n",
    "    * Bắt được tương tác giữa các feature (ví dụ experience + last_new_job + training_hours).\n",
    "* Trong thực nghiệm thường:\n",
    "    * F1 và/hoặc Recall cao hơn Logistic.\n",
    "    * Điều này cho thấy việc dùng cây quyết định đúng với giả thiết EDA: quan hệ không đơn thuần tuyến tính."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eec8dd",
   "metadata": {},
   "source": [
    "### **Training**\n",
    "\n",
    "Thực hiện tìm kiếm bộ tham số tối ưu (**Grid Search**) cho mô hình Random Forest dựa trên **F1-score** trên tập Validation:\n",
    "\n",
    "1.  **Không gian tìm kiếm:**\n",
    "    * `n_estimators`: [80, 100] (Số lượng cây).\n",
    "    * `max_depth`: [5, 6] (Độ sâu tối đa của cây - kiểm soát độ phức tạp).\n",
    "    * `min_samples_split`: [5, 10] (Số lượng mẫu tối thiểu để chia nút - chống overfitting).\n",
    "\n",
    "2.  **Quy trình:**\n",
    "    * Duyệt qua từng tổ hợp tham số.\n",
    "    * Huấn luyện mô hình trên `X_train`, `y_train`.\n",
    "    * Dự báo và đánh giá trên tập `X_val` (sử dụng ngưỡng mặc định).\n",
    "\n",
    "3.  **Kết quả:**\n",
    "    * Lưu lại mô hình (`best_rf`) và bộ tham số có **F1-score cao nhất**.\n",
    "    * Xuất ra các chỉ số đánh giá chi tiết (Accuracy, Precision, Recall, F1) của mô hình tốt nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4934c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thực hiện Grid Search cho Random Forest...\n",
      "\n",
      "[n_estimators=80, max_depth=5, min_samples_split=5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 80/80 [02:07<00:00,  1.60s/it, train=2.1860, val=2.2913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5949\n",
      "\n",
      "[n_estimators=80, max_depth=5, min_samples_split=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 80/80 [02:01<00:00,  1.51s/it, train=2.1807, val=2.2907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5948\n",
      "\n",
      "[n_estimators=80, max_depth=6, min_samples_split=5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 80/80 [01:39<00:00,  1.25s/it, train=1.9219, val=2.1314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5879\n",
      "\n",
      "[n_estimators=80, max_depth=6, min_samples_split=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 80/80 [02:07<00:00,  1.59s/it, train=1.9243, val=2.1311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5875\n",
      "\n",
      "[n_estimators=100, max_depth=5, min_samples_split=5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 100/100 [02:54<00:00,  1.75s/it, train=2.0849, val=2.1948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6020\n",
      "\n",
      "[n_estimators=100, max_depth=5, min_samples_split=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 100/100 [02:15<00:00,  1.36s/it, train=2.0771, val=2.1943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6012\n",
      "\n",
      "[n_estimators=100, max_depth=6, min_samples_split=5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 100/100 [02:29<00:00,  1.49s/it, train=1.7585, val=1.9891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5983\n",
      "\n",
      "[n_estimators=100, max_depth=6, min_samples_split=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest: 100%|██████████| 100/100 [03:02<00:00,  1.83s/it, train=1.7584, val=1.9889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.5980\n",
      "\n",
      "Bộ tham số tốt nhất\n",
      "  n_estimators      = 100\n",
      "  max_depth         = 5\n",
      "  min_samples_split = 5\n",
      "  best_threshold    = 0.0302\n",
      "\n",
      "Metrics tốt nhất trên Validation:\n",
      "  Accuracy         : 0.7794\n",
      "  Precision        : 0.5388\n",
      "  Recall           : 0.6820\n",
      "  F1-score         : 0.6020\n",
      "  Threshold        : 0.0302\n",
      "  Confusion Matrix :\n",
      "[[2347  547]\n",
      " [ 298  639]]\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [80, 100]\n",
    "max_depth_list    = [5, 6]\n",
    "min_samples_list  = [5, 10]\n",
    "\n",
    "best_rf = None\n",
    "best_rf_f1 = -1.0\n",
    "best_rf_params = None\n",
    "best_rf_threshold = None\n",
    "\n",
    "print(\"Thực hiện Grid Search cho Random Forest...\\n\")\n",
    "\n",
    "for n_est in n_estimators_list:\n",
    "    for depth in max_depth_list:\n",
    "        for min_s in min_samples_list:\n",
    "            print(f\"[n_estimators={n_est}, max_depth={depth}, min_samples_split={min_s}]\")\n",
    "\n",
    "            rf_tmp = RandomForest(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                max_features=\"sqrt\",\n",
    "                min_samples_split=min_s,\n",
    "                random_state=RANDOM_STATE,\n",
    "            )\n",
    "            rf_tmp.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "            y_val_prob_tmp = rf_tmp.predict_proba(X_val)\n",
    "\n",
    "            t_tmp, f1_tmp = find_best_threshold(y_val, y_val_prob_tmp, n_points=200)\n",
    "\n",
    "            metrics_tmp = evaluate_binary_classification(\n",
    "                y_true=y_val,\n",
    "                y_prob=y_val_prob_tmp,\n",
    "                threshold=t_tmp,\n",
    "            )\n",
    "\n",
    "            print(f\"  F1-score validation = {metrics_tmp['f1']:.4f}\\n\")\n",
    "            \n",
    "            if metrics_tmp[\"f1\"] > best_rf_f1:\n",
    "                best_rf_f1 = metrics_tmp[\"f1\"]\n",
    "                best_rf = rf_tmp\n",
    "                best_rf_params = (n_est, depth, min_s, metrics_tmp)\n",
    "                best_rf_threshold = t_tmp\n",
    "\n",
    "print(\"Bộ tham số tốt nhất\")\n",
    "print(\"  n_estimators      =\", best_rf_params[0])\n",
    "print(\"  max_depth         =\", best_rf_params[1])\n",
    "print(\"  min_samples_split =\", best_rf_params[2])\n",
    "print(f\"  best_threshold    = {best_rf_threshold:.4f}\")\n",
    "\n",
    "m_best = best_rf_params[3]\n",
    "print(\"\\nMetrics tốt nhất trên Validation:\")\n",
    "print(f\"  Accuracy         : {m_best['accuracy']:.4f}\")\n",
    "print(f\"  Precision        : {m_best['precision']:.4f}\")\n",
    "print(f\"  Recall           : {m_best['recall']:.4f}\")\n",
    "print(f\"  F1-score         : {m_best['f1']:.4f}\")\n",
    "print(f\"  Threshold        : {best_rf_threshold:.4f}\")\n",
    "print(f\"  Confusion Matrix :\\n{m_best['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1940456",
   "metadata": {},
   "source": [
    "#### **Nhận xét về quá trình huấn luyện**\n",
    "\n",
    "Quá trình huấn luyện Random Forest diễn ra ổn định và nhất quán giữa các bộ tham số. Các mô hình với cùng cấu hình độ sâu (`max_depth`) cho thấy hành vi gần giống nhau, cả về loss lẫn F1-score. Điều này cho thấy mô hình **không quá nhạy cảm với `min_samples_split`**, nhưng lại **nhạy cảm với độ sâu và số lượng cây**. Ngoài ra thời gian training lâu hơn khá nhiều so với Logistic Regression vì Random Forest phải xây dựng rất nhiều cây (Decision Tree), và mỗi cây phải thử rất nhiều split trên nhiều feature để tìm điểm chia tốt nhất. Logistic Regression chỉ cần tối ưu một hàm tuyến tính bằng phép nhân ma trận, nên tính toán đơn giản và nhanh hơn rất nhiều.\n",
    "\n",
    "**Một điểm dễ thấy là:**\n",
    "\n",
    "* Với **`max_depth = 5`**, mô hình ổn định và đạt F1 cao hơn.\n",
    "* Khi tăng lên **`max_depth = 6`**, train loss giảm (mô hình phức tạp hơn) nhưng validation loss lại không cải thiện và F1 giảm nhẹ.\n",
    "    *Điều này cho thấy mô hình bắt đầu “học quá sâu”, nhưng không nắm bắt được thêm thông tin hữu ích từ dữ liệu — một dấu hiệu của **quá khớp (overfitting) nhẹ** theo chiều sâu.*\n",
    "\n",
    "Trong khi đó, việc tăng số cây từ **80 → 100** consistently giúp cải thiện nhẹ hiệu năng. Điều này đúng với bản chất Random Forest: thêm cây → mô hình ổn định và tổng hợp tín hiệu tốt hơn, đặc biệt trong dữ liệu có nhiều biến one-hot.\n",
    "\n",
    "\n",
    "**Về phần bộ tham số tối ưu:** Bộ tham số tốt nhất được xác định là:\n",
    " * `n_estimators = 100`\n",
    " * `max_depth = 5`\n",
    " * `min_samples_split = 5`\n",
    " * `best_threshold = 0.0302`\n",
    "\n",
    "    **Giải thích chi tiết:**\n",
    "\n",
    "    1.  **`n_estimators = 100`**: 100 cây giúp mô hình ổn định và giảm phương sai hơn so với 80 cây.\n",
    "    2.  **`max_depth = 5`**: Độ sâu này cho thấy mô hình không cần quá phức tạp — sâu hơn (`depth=6`) không mang lại giá trị mà còn làm validation loss tăng.\n",
    "    3.  **`min_samples_split = 5`**: Tương thích với `depth=5`, cho phép chia nhánh linh hoạt hơn nhưng vẫn giữ được tính khái quát.\n",
    "    4.  **`best_threshold = 0.0302`**:\n",
    "        * Điểm quan trọng nhất là threshold rất thấp. Điều này phản ánh xác suất dự đoán từ Random Forest phân bố khá thấp, đặc biệt cho lớp dương.\n",
    "        * Để tối ưu F1-score, ta phải hạ threshold xuống mức rất nhỏ.\n",
    "        * *Đây là hành vi thường thấy ở Random Forest với dữ liệu tồn tại nhiều biến one-hot và phân bố lệch — xác suất mô hình thường không được calibrate tốt, nhưng phân hạng vẫn tương đối ổn.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3b993",
   "metadata": {},
   "source": [
    "### **Đánh giá với test set**\n",
    "Thực hiện quy trình đánh giá chuyên sâu cho mô hình Random Forest đã được tinh chỉnh (`best_rf`):\n",
    "\n",
    "1.  **Dự báo xác suất:** Tính xác suất (`predict_proba`) trên tập Validation và Test.\n",
    "2.  **Đánh giá toàn diện:**\n",
    "    * Áp dụng ngưỡng tối ưu này để đánh giá lại tập Validation và **Test**.\n",
    "    * Tính thêm chỉ số **ROC-AUC** để đo khả năng phân loại tổng quát.\n",
    "3.  **So sánh & Báo cáo:**\n",
    "    * Xuất bảng so sánh trực quan các chỉ số (Accuracy, Precision, Recall, F1, AUC) giữa Validation và Test để kiểm tra độ ổn định (tránh Overfitting).\n",
    "    * Hiển thị Ma trận nhầm lẫn (Confusion Matrix) để phân tích chi tiết các lỗi dự báo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274d79bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (validation) = 0.0302\n",
      " F1-score (validation) = 0.6020\n",
      "\n",
      "============================================================\n",
      "             Random Forest – Validation vs Test\n",
      "============================================================\n",
      "Metric          | Validation   | Test        \n",
      "------------------------------------------------------------\n",
      "accuracy        |       0.7794 |       0.7802\n",
      "precision       |       0.5388 |       0.5555\n",
      "recall          |       0.6820 |       0.6786\n",
      "f1              |       0.6020 |       0.6109\n",
      "threshold       |       0.0302 |       0.0302\n",
      "best_threshold  |       0.0302 |       0.0302\n",
      "roc_auc         |       0.7790 |       0.7749\n",
      "------------------------------------------------------------\n",
      "\n",
      "Confusion matrix (Validation):\n",
      "[[2347  547]\n",
      " [ 298  639]]\n",
      "\n",
      "Confusion matrix (Test):\n",
      "[[2328  529]\n",
      " [ 313  661]]\n"
     ]
    }
   ],
   "source": [
    "y_val_prob_rf  = best_rf.predict_proba(X_val)\n",
    "y_test_prob_rf = best_rf.predict_proba(X_test)\n",
    "\n",
    "best_t_rf  = best_rf_threshold\n",
    "best_f1_rf = best_rf_f1\n",
    "\n",
    "metrics_rf_val_best  = evaluate_binary_classification(y_val,  y_val_prob_rf,  threshold=best_t_rf)\n",
    "metrics_rf_test_best = evaluate_binary_classification(y_test, y_test_prob_rf, threshold=best_t_rf)\n",
    "\n",
    "auc_val_rf  = roc_auc_score(y_val,  y_val_prob_rf)\n",
    "auc_test_rf = roc_auc_score(y_test, y_test_prob_rf)\n",
    "\n",
    "print(f\"Best threshold (validation) = {best_t_rf:.4f}\\n F1-score (validation) = {best_f1_rf:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"             Random Forest – Validation vs Test\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"{'Metric':15s} | {'Validation':12s} | {'Test':12s}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for k in metrics_rf_val_best.keys():\n",
    "    if k == \"confusion_matrix\":\n",
    "        continue\n",
    "\n",
    "    v_val  = metrics_rf_val_best[k]\n",
    "    v_test = metrics_rf_test_best[k]\n",
    "\n",
    "    if isinstance(v_val, float):\n",
    "        print(f\"{k:15s} | {v_val:12.4f} | {v_test:12.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:15s} | {str(v_val):12s} | {str(v_test):12s}\")\n",
    "\n",
    "print(f\"{'best_threshold':15s} | {best_t_rf:12.4f} | {best_t_rf:12.4f}\")\n",
    "print(f\"{'roc_auc':15s} | {auc_val_rf:12.4f} | {auc_test_rf:12.4f}\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"\\nConfusion matrix (Validation):\")\n",
    "print(metrics_rf_val_best[\"confusion_matrix\"])\n",
    "\n",
    "print(\"\\nConfusion matrix (Test):\")\n",
    "print(metrics_rf_test_best[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722985a8",
   "metadata": {},
   "source": [
    "#### **Nhận xét**\n",
    "\n",
    "  1. Độ ổn định giữa Validation và Test rất tốt\n",
    "\n",
    "     So sánh hiệu năng giữa hai tập dữ liệu cho thấy sự ổn định tuyệt vời:\n",
    "\n",
    "        | Metric | Val | Test | Nhận xét |\n",
    "        | :--- | :---: | :---: | :--- |\n",
    "        | **Accuracy** | 0.7794 | **0.7802** | Giữ nguyên |\n",
    "        | **Precision** | 0.5388 | **0.5555** | Tăng nhẹ |\n",
    "        | **Recall** | 0.6820 | **0.6786** | Giảm rất ít |\n",
    "        | **F1-Score** | 0.6020 | **0.6109** | Tăng nhẹ |\n",
    "        | **ROC-AUC** | 0.7790 | **0.7749** | Tương đương nhau |\n",
    "\n",
    "     **Kết luận:** Random Forest **không bị Overfit** và có khả năng tổng quát hóa (generalize) rất tốt trên tập Test. Đây là yếu tố cực kỳ quan trọng đối với các mô hình dữ liệu dạng bảng (tabular).\n",
    "\n",
    "  2. So sánh với Logistic Regression (Trade-off)\n",
    "        | Metric | Logistic | Random Forest | Nhận xét |\n",
    "        | :--- | :---: | :---: | :--- |\n",
    "        | **Precision** | ~0.50 | **~0.55** | RF tốt hơn (Ít báo động giả hơn) |\n",
    "        | **Recall** | **~0.73** | ~0.68 | Logistic cao hơn (Bắt được nhiều người nghỉ hơn) |\n",
    "        | **F1-Score** | **0.615** | 0.611 | Logistic nhỉnh hơn một chút xíu |\n",
    "        | **AUC** | **0.79** | 0.78 | Gần tương đương |\n",
    "\n",
    "        **Phân tích:**\n",
    "\n",
    "        * **Random Forest:** Nghiêng về độ chính xác (**Precision**), giúp giảm bớt các dự báo sai (False Positive).\n",
    "        * **Logistic Regression:** Nghiêng về độ bao phủ (**Recall**), chấp nhận bắt nhầm để không bỏ sót.\n",
    "\n",
    "  3. Điểm thú vị: Ngưỡng (Threshold) cực thấp (0.0302)\n",
    "        Để đạt F1 cao nhất, ngưỡng cắt của RF hạ xuống còn **0.0302**.\n",
    "        * **Ý nghĩa:** Chỉ cần xác suất > 3% là mô hình đã dự báo \"nghỉ việc\".\n",
    "        * **Lý do:** Các mô hình cây (Tree-based) thường trả ra xác suất không được hiệu chỉnh tốt (uncalibrated probabilities), thường tập trung ở mức thấp đối với dữ liệu mất cân bằng. Nếu dùng ngưỡng mặc định 0.5, Recall sẽ cực tệ.\n",
    "        * **Kết luận:** Dù xác suất thấp, nhưng khả năng phân loại (ranking) của mô hình vẫn tốt (thể hiện qua AUC ~ 0.78).\n",
    "\n",
    "  4. Phân tích Ma trận nhầm lẫn (Confusion Matrix)\n",
    "        Kết quả trên tập Test:\n",
    "\n",
    "        ```text\n",
    "        [[2328  529]\n",
    "        [ 313  661]]\n",
    "        ```\n",
    "        * **False Positive giảm mạnh:**\n",
    "            * So với Logistic Regression (647 ca), Random Forest chỉ có **529 ca**.\n",
    "            * **Ý nghĩa:** Điều này giúp bộ phận HR đỡ tốn công sức và nguồn lực để \"chăm sóc nhầm\" những nhân viên vốn dĩ vẫn muốn ở lại (giảm lãng phí).\n",
    "\n",
    "        * **False Negative tăng lên:**\n",
    "            * So với Logistic (254 ca), Random Forest bỏ sót **313 ca**.\n",
    "            * **Ý nghĩa:** Đây là sự đánh đổi (Trade-off) tất yếu. Muốn mô hình có độ chính xác cao hơn (Precision) thì phải chấp nhận rủi ro bỏ sót một số trường hợp nhân viên nghỉ việc.\n",
    "\n",
    "**Tổng kết: Random Forest vs Logistic Regression**\n",
    "\n",
    "  1. **Điểm mạnh của Random Forest:**\n",
    "     * Hoạt động ổn định.\n",
    "     * **Precision cao hơn:** Dự báo đáng tin cậy hơn.\n",
    "     * Ít báo động giả (False Positive) hơn.\n",
    "\n",
    "  2. **Điểm yếu của Random Forest:**\n",
    "     * **Recall** và **ROC-AUC** thấp hơn một chút so với Logistic.\n",
    "\n",
    "  3. **Nhận định chung:**\n",
    "     * **Logistic Regression** vẫn đang là một Baseline cực kỳ mạnh mẽ (nhờ vào quá trình Feature Engineering tốt).\n",
    "     * **Random Forest** đứng vị trí thứ 2 với ưu thế về sự ổn định và độ chính xác.\n",
    "     * **Kỳ vọng:** Mô hình tiếp theo (**XGBoost**) sẽ là sự kết hợp điểm mạnh của cả hai: Tăng Precision mà không làm giảm Recall quá nhiều.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2a04",
   "metadata": {},
   "source": [
    "## **Mô hình 3: XGBoost (Gradient Boosting)**\n",
    "\n",
    "#### **1. Lý do lựa chọn**\n",
    "Khác với **Random Forest** sử dụng kỹ thuật Bagging (xây dựng các cây độc lập để giảm phương sai), **XGBoost** áp dụng kỹ thuật **Boosting** nhằm tối ưu hóa độ chính xác:\n",
    "* **Học tuần tự (Sequential Learning):** Các cây quyết định được xây dựng nối tiếp nhau, trong đó mỗi cây mới sẽ tập trung giải quyết các lỗi sai (residuals) mà chuỗi cây trước đó để lại.\n",
    "* **Tối ưu hóa bậc hai:** Sử dụng thông tin từ cả Gradient (đạo hàm bậc 1) và Hessian (đạo hàm bậc 2) của hàm mất mát logistic để định hướng việc xây dựng cây, giúp mô hình hội tụ nhanh và chính xác hơn.\n",
    "* **Hiệu năng vượt trội:** Được công nhận là thuật toán mạnh mẽ nhất (Champion) đối với các bài toán dữ liệu dạng bảng (Tabular Data).\n",
    "\n",
    "#### **2. Chiến lược thực hiện**\n",
    "Dự án sử dụng phiên bản XGBoost tự cài đặt bằng **NumPy** để kiểm soát hoàn toàn luồng tính toán:\n",
    "* **Core:** Xây dựng Class `XGBoost` dựa trên `RegressionTree` kết hợp cơ chế cập nhật trọng số Boosting.\n",
    "* **Hyperparameter Tuning:** Tinh chỉnh các tham số chủ chốt gồm `n_rounds`, `max_depth`, và `learning_rate` thông qua Grid Search.\n",
    "* **Threshold Tuning:** Tìm kiếm ngưỡng phân loại tối ưu (Best Threshold) dựa trên chỉ số F1-Score trên tập Validation để cực đại hóa hiệu năng thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50bebc",
   "metadata": {},
   "source": [
    "### **Training**\n",
    "\n",
    "Thực hiện tìm kiếm bộ tham số tối ưu (**Grid Search**) cho mô hình XGBoost nhằm cực đại hóa **F1-score** trên tập Validation:\n",
    "\n",
    "1.  **Không gian tìm kiếm đa chiều:**\n",
    "    * `n_rounds`: [80, 120] (Số vòng lặp boosting).\n",
    "    * `max_depth`: [4, 5] (Độ sâu cây).\n",
    "    * `learning_rate`: [0.05, 0.1] (Tốc độ học).\n",
    "    * `subsample` & `colsample`: [0.8, 1.0] (Tỷ lệ mẫu và đặc trưng để chống overfitting).\n",
    "\n",
    "2.  **Quy trình tối ưu kép:**\n",
    "    * **Huấn luyện:** Duyệt qua từng tổ hợp tham số, huấn luyện với cơ chế **Early Stopping** (dừng nếu val loss không giảm sau 20 rounds).\n",
    "    * **Tối ưu ngưỡng:** Với mỗi mô hình, tự động tìm **ngưỡng cắt (threshold)** tốt nhất trên tập Validation thay vì dùng mặc định 0.5.\n",
    "\n",
    "3.  **Kết quả:**\n",
    "    * Lưu lại mô hình (`best_xgb`) và bộ tham số mang lại F1-score cao nhất.\n",
    "    * Ghi nhận ngưỡng tối ưu (`best_xgb_threshold`) để áp dụng đánh giá sau cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de38e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang Grid Search XGBoost...\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.01, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:16<00:00,  4.95it/s, train=0.5116, val=0.5162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6152\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.01, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:20<00:00,  3.85it/s, train=0.5098, val=0.5147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6157\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.01, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:20<00:00,  3.82it/s, train=0.5119, val=0.5163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6148\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.01, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:25<00:00,  3.08it/s, train=0.5102, val=0.5146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6103\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.05, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:16<00:00,  4.94it/s, train=0.4217, val=0.4413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6209\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.05, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:20<00:00,  3.87it/s, train=0.4204, val=0.4411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6208\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.05, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:20<00:00,  3.92it/s, train=0.4221, val=0.4407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6215\n",
      "\n",
      "[n_rounds=80, max_depth=4, lr=0.05, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:25<00:00,  3.14it/s, train=0.4214, val=0.4408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6195\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.01, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:21<00:00,  3.79it/s, train=0.5056, val=0.5138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6172\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.01, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:26<00:00,  2.98it/s, train=0.5033, val=0.5122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6134\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.01, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:26<00:00,  3.02it/s, train=0.5058, val=0.5142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6137\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.01, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:32<00:00,  2.47it/s, train=0.5041, val=0.5125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6146\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.05, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:20<00:00,  3.87it/s, train=0.4070, val=0.4412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6209\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.05, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:32<00:00,  2.49it/s, train=0.4056, val=0.4411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6198\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.05, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:38<00:00,  2.08it/s, train=0.4085, val=0.4400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6219\n",
      "\n",
      "[n_rounds=80, max_depth=5, lr=0.05, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 80/80 [00:56<00:00,  1.41it/s, train=0.4081, val=0.4411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6174\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.01, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:39<00:00,  3.05it/s, train=0.4768, val=0.4838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6183\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.01, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:31<00:00,  3.80it/s, train=0.4752, val=0.4826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6169\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.01, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:31<00:00,  3.84it/s, train=0.4769, val=0.4837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6194\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.01, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:38<00:00,  3.15it/s, train=0.4760, val=0.4828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6173\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.05, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:30<00:00,  3.94it/s, train=0.4132, val=0.4399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6216\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.05, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:30<00:00,  3.99it/s, train=0.4118, val=0.4401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6210\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.05, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:31<00:00,  3.82it/s, train=0.4151, val=0.4392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6261\n",
      "\n",
      "[n_rounds=120, max_depth=4, lr=0.05, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:55<00:00,  2.17it/s, train=0.4137, val=0.4400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6197\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.01, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:31<00:00,  3.78it/s, train=0.4690, val=0.4811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6171\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.01, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [01:10<00:00,  1.69it/s, train=0.4665, val=0.4794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6161\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.01, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:39<00:00,  3.04it/s, train=0.4689, val=0.4810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6187\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.01, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:56<00:00,  2.11it/s, train=0.4673, val=0.4798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6150\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.05, subsample=0.8, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost:  99%|█████████▉| 119/120 [00:43<00:00,  2.73it/s, train=0.3947, val=0.4416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] XGBoost dừng tại round 120 | best_val_loss = 0.4409, số cây dùng thực tế = 100\n",
      "  F1-score validation = 0.6202\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.05, subsample=0.8, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:55<00:00,  2.17it/s, train=0.3934, val=0.4411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6178\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.05, subsample=1.0, colsample=0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost: 100%|██████████| 120/120 [00:44<00:00,  2.68it/s, train=0.3982, val=0.4401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1-score validation = 0.6200\n",
      "\n",
      "[n_rounds=120, max_depth=5, lr=0.05, subsample=1.0, colsample=1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost:  96%|█████████▌| 115/120 [00:47<00:02,  2.42it/s, train=0.3977, val=0.4407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Early stopping] XGBoost dừng tại round 116 | best_val_loss = 0.4406, số cây dùng thực tế = 96\n",
      "  F1-score validation = 0.6182\n",
      "\n",
      "\n",
      "Bộ tham số tốt nhất:\n",
      "  n_rounds      = 120\n",
      "  max_depth     = 4\n",
      "  learning_rate = 0.05\n",
      "  subsample     = 1.0\n",
      "  colsample     = 0.8\n",
      "  Best F1(val)  = 0.6261\n",
      "  Best threshold = 0.286\n"
     ]
    }
   ],
   "source": [
    "# Grid Search XGBoost\n",
    "n_rounds_list    = [80, 120]\n",
    "max_depth_list   = [4, 5]\n",
    "lr_list          = [0.01, 0.05]\n",
    "subsample_list   = [0.8, 1.0]\n",
    "colsample_list   = [0.8, 1.0]\n",
    "\n",
    "best_xgb = None\n",
    "best_xgb_f1 = -1.0\n",
    "best_xgb_params = None\n",
    "best_xgb_threshold = 0.5\n",
    "\n",
    "print(\"Đang Grid Search XGBoost...\\n\")\n",
    "\n",
    "for n_r in n_rounds_list:\n",
    "    for depth in max_depth_list:\n",
    "        for lr_ in lr_list:\n",
    "            for sub_ in subsample_list:\n",
    "                for col_ in colsample_list:\n",
    "                    print(f\"[n_rounds={n_r}, max_depth={depth}, lr={lr_}, subsample={sub_}, colsample={col_}]\")\n",
    "                    \n",
    "                    model = XGBoost(n_rounds=n_r, max_depth=depth, learning_rate=lr_, lambda_reg=1.0, subsample=sub_, colsample_bytree=col_, min_child_weight=1e-2, min_gain_to_split=0.0, early_stopping=True, patience=20, random_state=RANDOM_STATE)\n",
    "                    model.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "                    y_val_prob_tmp = model.predict_proba(X_val)\n",
    "\n",
    "                    t_tmp, f1_tmp = find_best_threshold(y_val, y_val_prob_tmp, n_points=200)\n",
    "\n",
    "                    metrics_tmp = evaluate_binary_classification(y_true=y_val,y_prob=y_val_prob_tmp,threshold=t_tmp)\n",
    "\n",
    "                    print(f\"  F1-score validation = {metrics_tmp['f1']:.4f}\\n\")\n",
    "\n",
    "                    if f1_tmp > best_xgb_f1:\n",
    "                        best_xgb_f1 = f1_tmp\n",
    "                        best_xgb = model\n",
    "                        best_xgb_threshold = t_tmp\n",
    "                        best_xgb_params = (n_r, depth, lr_, sub_, col_)\n",
    "\n",
    "print(\"\\nBộ tham số tốt nhất:\")\n",
    "print(f\"  n_rounds      = {best_xgb_params[0]}\")\n",
    "print(f\"  max_depth     = {best_xgb_params[1]}\")\n",
    "print(f\"  learning_rate = {best_xgb_params[2]}\")\n",
    "print(f\"  subsample     = {best_xgb_params[3]}\")\n",
    "print(f\"  colsample     = {best_xgb_params[4]}\")\n",
    "print(f\"  Best F1(val)  = {best_xgb_f1:.4f}\")\n",
    "print(f\"  Best threshold = {best_xgb_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee29633",
   "metadata": {},
   "source": [
    "#### **Nhận xét về quá trình huấn luyện XGBoost**\n",
    "\n",
    "Quá trình Grid Search của XGBoost cho thấy mô hình phản ứng **ổn định và nhất quán** với tất cả các tổ hợp siêu tham số. Sự khác biệt giữa các cấu hình chủ yếu đến từ `learning_rate` và số vòng boosting, trong khi các tham số như `subsample` và `colsample` chỉ tạo ra khác biệt nhỏ về F1.\n",
    "\n",
    "**Các xu hướng nổi bật:**\n",
    "* **Learning Rate:** `0.05` cho F1-score cao hơn đáng kể so với `0.01` ở hầu hết mọi cấu hình.\n",
    "* **Độ sâu (Max Depth):** Các cấu hình với `max_depth = 4` hoạt động hiệu quả hơn `depth = 5`. Dù độ sâu lớn giúp train loss thấp hơn, nhưng lại không cải thiện (thậm chí làm giảm nhẹ) kết quả trên validation.\n",
    "* **Số vòng lặp (Rounds):** Khi tăng từ **80 → 120**, mô hình có thêm cơ hội học các tương tác phức tạp hơn nhưng không bị overfit, nhờ cơ chế *Early Stopping* kích hoạt đúng lúc.\n",
    "\n",
    "**Điểm sáng:** Các cấu hình tốt đều **hội tụ về cùng một vùng** (`lr 0.05`, `depth 4`, `subsample 1.0`, `colsample 0.8`). Điều này cho thấy không có sự dao động lớn giữa các thử nghiệm – dấu hiệu của một mô hình mạnh và dữ liệu rất phù hợp với thuật toán Boosting.\n",
    "\n",
    "**Về phần bộ tham số tối ưu**, bộ tham số tốt nhất được xác định là:\n",
    " * `n_rounds` = 120\n",
    " * `max_depth` = 4\n",
    " * `learning_rate` = 0.05\n",
    " * `subsample` = 1.0\n",
    " * `colsample` = 0.8\n",
    " * **Best Threshold** = 0.286\n",
    " * **Best F1 (val)** = 0.6261\n",
    "\n",
    " **Tại sao bộ tham số này hợp lý?**\n",
    "  1.  **`learning_rate = 0.05`**: Cho phép mô hình học sâu nhưng vẫn kiểm soát tốt overfitting.\n",
    "  2.  **`max_depth = 4`**: Đảm bảo mỗi cây không quá phức tạp, tránh việc *fitting* thừa lên các nhiễu (noise) của dữ liệu One-hot.\n",
    "  3.  **`subsample = 1.0` & `colsample = 0.8`**: Giúp tăng độ đa dạng cây nhưng vẫn giữ được đủ thông tin quan trọng cho mỗi vòng boosting.\n",
    "  4.  **`threshold = 0.286`**: Phản ánh xác suất dự đoán của XGBoost tương đối \"đậm\" và được hiệu chỉnh (calibrate) tốt hơn Random Forest. Ngưỡng này cho phép cân bằng tối ưu giữa Precision và Recall.\n",
    "\n",
    "**Kết luận:**\n",
    "Quá trình Grid Search khẳng định **XGBoost** học ổn định, không bị Overfit và **liên tục vượt trội** hơn hai mô hình còn lại. Việc các cấu hình tốt hội tụ tại cùng một vùng tham số chứng tỏ dữ liệu rất phù hợp với Boosting và XGBoost đã khai thác thành công bản chất phi tuyến của tập dữ liệu HR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331f27c",
   "metadata": {},
   "source": [
    "### **Đánh giá trên test set**\n",
    "\n",
    "Thực hiện bước đánh giá cuối cùng cho mô hình Champion (XGBoost) với bộ tham số và ngưỡng cắt (threshold) đã tối ưu:\n",
    "\n",
    "1.  **Áp dụng tham số:** Sử dụng mô hình `best_xgb` và ngưỡng `best_xgb_threshold` (tìm được từ Validation) để dự báo trên tập **Test**.\n",
    "2.  **Tính toán Metrics:** Tính toàn bộ các chỉ số quan trọng (F1, Recall, Precision) và **ROC-AUC**.\n",
    "3.  **So sánh đối chứng (Validation vs Test):**\n",
    "    * Xuất bảng so sánh trực quan để kiểm tra khả năng tổng quát hóa (Generalization).\n",
    "    * *Mục tiêu:* Đảm bảo điểm số trên Test tương đương Validation (không bị Overfitting).\n",
    "4.  **Phân tích lỗi:** Hiển thị Ma trận nhầm lẫn (Confusion Matrix) để nhìn rõ số lượng mẫu dự báo đúng/sai thực tế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf31f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBOOST:\n",
      "Best params: n_rounds=120, max_depth=4, lr=0.05, subsample=1.0, colsample=0.8\n",
      "Best F1-score(validation) = 0.6261 - threshold = 0.286\n",
      "\n",
      "======================================================================\n",
      "                    XGBoost – Validation vs Test\n",
      "======================================================================\n",
      "Best threshold (val): 0.2864, F1(val) = 0.6261\n",
      "\n",
      "Metric          | Validation   | Test        \n",
      "----------------------------------------------------------------------\n",
      "accuracy        |       0.7883 |       0.7873\n",
      "precision       |       0.5511 |       0.5635\n",
      "recall          |       0.7247 |       0.7238\n",
      "f1              |       0.6261 |       0.6337\n",
      "threshold       |       0.2864 |       0.2864\n",
      "roc_auc         |       0.7970 |       0.8035\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Confusion matrix (Validation):\n",
      "[[2341  553]\n",
      " [ 258  679]]\n",
      "\n",
      "Confusion matrix (Test):\n",
      "[[2311  546]\n",
      " [ 269  705]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best XGBOOST:\")\n",
    "print(f\"Best params: n_rounds={best_xgb_params[0]}, \"\n",
    "      f\"max_depth={best_xgb_params[1]}, lr={best_xgb_params[2]}, \"\n",
    "      f\"subsample={best_xgb_params[3]}, colsample={best_xgb_params[4]}\")\n",
    "print(f\"Best F1-score(validation) = {best_xgb_f1:.4f} - threshold = {best_xgb_threshold:.3f}\")\n",
    "\n",
    "y_val_prob_xgb = best_xgb.predict_proba(X_val)\n",
    "metrics_xgb_val = evaluate_binary_classification(y_true=y_val, y_prob=y_val_prob_xgb, threshold=best_xgb_threshold)\n",
    "\n",
    "y_test_prob_xgb = best_xgb.predict_proba(X_test)\n",
    "metrics_xgb_test = evaluate_binary_classification(y_true=y_test, y_prob=y_test_prob_xgb, threshold=best_xgb_threshold)\n",
    "\n",
    "auc_val_xgb = roc_auc_score(y_val, y_val_prob_xgb)\n",
    "auc_test_xgb = roc_auc_score(y_test, y_test_prob_xgb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    XGBoost – Validation vs Test\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best threshold (val): {best_xgb_threshold:.4f}, F1(val) = {best_xgb_f1:.4f}\\n\")\n",
    "\n",
    "print(f\"{'Metric':15s} | {'Validation':12s} | {'Test':12s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for k in metrics_xgb_val.keys():\n",
    "    if k == \"confusion_matrix\":\n",
    "        continue\n",
    "\n",
    "    v_val = metrics_xgb_val[k]\n",
    "    v_test = metrics_xgb_test[k]\n",
    "\n",
    "    if isinstance(v_val, float):\n",
    "        print(f\"{k:15s} | {v_val:12.4f} | {v_test:12.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:15s} | {str(v_val):12s} | {str(v_test):12s}\")\n",
    "\n",
    "print(f\"{'roc_auc':15s} | {auc_val_xgb:12.4f} | {auc_test_xgb:12.4f}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"\\nConfusion matrix (Validation):\")\n",
    "print(metrics_xgb_val[\"confusion_matrix\"])\n",
    "\n",
    "print(\"\\nConfusion matrix (Test):\")\n",
    "print(metrics_xgb_test[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a74e46",
   "metadata": {},
   "source": [
    "#### **Nhận xét**\n",
    "  1. Độ ổn định tuyệt vời \n",
    "\n",
    "        Mô hình XGBoost thể hiện sự ổn định cao nhất trong cả 3 mô hình, chứng tỏ khả năng tổng quát hóa (generalization) xuất sắc:\n",
    "\n",
    "        | Metric | Val | Test | Nhận xét |\n",
    "        | :--- | :---: | :---: | :--- |\n",
    "        | **Accuracy** | 0.7883 | **0.7873** | Gần như giống nhau |\n",
    "        | **Precision** | 0.5511 | **0.5635** | Tăng nhẹ |\n",
    "        | **Recall** | 0.7247 | **0.7238** | Giữ nguyên (Giảm không đáng kể) |\n",
    "        | **F1-Score** | 0.6261 | **0.6337** | Tăng lên → Tín hiệu rất tốt |\n",
    "        | **ROC-AUC** | 0.7970 | **0.8035** | Cao nhất trong 3 mô hình |\n",
    "\n",
    "        **Kết luận:** Không có dấu hiệu Overfitting. Mô hình hoạt động tin cậy trên tập dữ liệu chưa từng thấy (Test set).\n",
    "\n",
    "  2. Dẫn đầu về F1-Score\n",
    "        \n",
    "        So sánh hiệu năng tổng thể trên tập Test:\n",
    "        * **Logistic Regression:** 0.6151\n",
    "        * **Random Forest:** 0.6109\n",
    "        * **XGBoost:** **0.6337**\n",
    "\n",
    "        **XGBoost dẫn đầu**, khẳng định vị thế vượt trội của thuật toán Gradient Boosting trên dữ liệu dạng bảng (Tabular Data).\n",
    "\n",
    "  3. Điểm cân bằng hoàn hảo (Precision vs Recall)\n",
    "        | Metric | Logistic | RF | XGBoost |\n",
    "        | :--- | :---: | :---: | :---: |\n",
    "        | **Precision** | 0.5267 | 0.5555 |  **0.5635** (Cao nhất) |\n",
    "        | **Recall** | 0.7392 | 0.6786 | **0.7238** (Tiệm cận Logistic) |\n",
    "\n",
    "        **Phân tích:**\n",
    "        * **Precision cao nhất:** Giảm thiểu số lượng báo động giả (False Positive) tốt nhất.\n",
    "        * **Recall ấn tượng:** Gần ngang ngửa Logistic, nghĩa là không bỏ sót nhiều nhân tài muốn ra đi.\n",
    "        * Đây là sự cân bằng tối ưu mà chúng ta tìm kiếm cho bài toán quản trị nhân sự.\n",
    "\n",
    "  4. Ngưỡng cắt (Threshold) hợp lý & Phân loại tốt\n",
    "        * **Threshold tối ưu:** `0.2864`.\n",
    "            * So sánh: Logistic (0.266) < XGBoost (0.286) < RF (0.03).\n",
    "            * **Nhận định:** Xác suất dự báo của XGBoost được hiệu chỉnh (calibrated) tốt hơn hẳn Random Forest, gần với phân phối thực tế hơn.\n",
    "        * **ROC-AUC (0.8035):** Cao nhất trong 3 mô hình, chứng tỏ khả năng phân biệt giữa hai lớp (Nghỉ việc vs Ở lại) là tốt nhất.\n",
    "\n",
    "  5. Phân tích Ma trận nhầm lẫn (Test Set)\n",
    "     Kết quả:\n",
    "        ```text\n",
    "        [[2311  546]\n",
    "        [ 269  705]]\n",
    "        ```\n",
    "     * **False Positive (546) - Báo động giả:**\n",
    "         * Kết quả nằm giữa Logistic (647) và Random Forest (529).\n",
    "         * *Nhận định:* Đây là mức \"hy sinh\" chấp nhận được về mặt độ chính xác (Precision) để đổi lấy khả năng bao quát (Recall) tốt hơn.\n",
    "\n",
    "     * **False Negative (269) - Bỏ sót rủi ro:**\n",
    "         * Thấp hơn đáng kể so với Random Forest (313) và chỉ nhỉnh hơn Logistic một chút (254).\n",
    "         * *Nhận định:* Mô hình hạn chế tối đa việc bỏ sót những nhân sự muốn nghỉ việc, đảm bảo tính an toàn cho kế hoạch nhân sự.\n",
    "\n",
    "**Tổng kết: XGBoost là mô hình tốt nhất** vì đã giải quyết xuất sắc bài toán **Cân bằng (Trade-off)** mà hai mô hình trước gặp phải:\n",
    "  1. **FN không quá cao như Random Forest** (giữ được Recall tốt).\n",
    "  2. **FP không quá cao như Logistic Regression** (giữ được Precision ổn).\n",
    "  3. **Kết quả:** Đạt **F1-Score cao nhất**, trở thành mô hình toàn diện nhất để đưa vào áp dụng thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17f345",
   "metadata": {},
   "source": [
    "## **So sánh & Tổng kết**\n",
    "- Tổng hợp Accuracy, Precision, Recall, F1 trên cùng tập Validation.\n",
    "- Dựa vào metric ưu tiên (ở đây là F1), chọn ra best model.\n",
    "- Nhận xét và phân tích kết quả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033c8125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "\t\t\tSo sánh các model\n",
      "=================================================================\n",
      "Model              | Accuracy  | Precision | Recall    | F1-score \n",
      "-----------------------------------------------------------------\n",
      "LogisticRegression | 0.7648     | 0.5267     | 0.7392     | 0.6151\n",
      "RandomForest       | 0.7802     | 0.5555     | 0.6786     | 0.6109\n",
      "XGBoost            | 0.7873     | 0.5635     | 0.7238     | 0.6337\n",
      "-----------------------------------------------------------------\n",
      "Best model theo F1 trên TEST: XGBoost (F1=0.6337)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "def summarize(name, metrics):\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": metrics[\"accuracy\"],\n",
    "        \"precision\": metrics[\"precision\"],\n",
    "        \"recall\": metrics[\"recall\"],\n",
    "        \"f1\": metrics[\"f1\"],\n",
    "    }\n",
    "\n",
    "rows_test = [\n",
    "    summarize(\"LogisticRegression\", metrics_log_test),\n",
    "    summarize(\"RandomForest\",       metrics_rf_test_best),\n",
    "    summarize(\"XGBoost\",            metrics_xgb_test),\n",
    "]\n",
    "\n",
    "best_model = max(rows_test, key=lambda r: r[\"f1\"])\n",
    "print(\"=\"*65)\n",
    "print(\"\\t\\t\\tSo sánh các model\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "print(f\"{'Model':18s} | {'Accuracy':9s} | {'Precision':9s} | {'Recall':9s} | {'F1-score':9s}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for r in rows_test:\n",
    "    print(f\"{r['model']:18s} | {r['accuracy']:.4f}     | {r['precision']:.4f}     | {r['recall']:.4f}     | {r['f1']:.4f}\")\n",
    "\n",
    "print(\"-\"*65)\n",
    "print(f\"Best model theo F1 trên TEST: {best_model['model']} (F1={best_model['f1']:.4f})\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a39bd6",
   "metadata": {},
   "source": [
    "### **Phân tích và nhận xét kết luận**\n",
    "\n",
    "Bảng kết quả thực nghiệm trên bộ dữ liệu **TEST** đã vẽ nên bức tranh rõ ràng về hành vi của ba mô hình (Logistic Regression, Random Forest, XGBoost). Dưới đây là những nhận định chi tiết về mức độ phù hợp của từng thuật toán đối với bài toán HR Analytics:\n",
    "\n",
    "#### 1. Logistic Regression (Baseline mạnh về Recall)\n",
    "Mặc dù là mô hình tuyến tính đơn giản, Logistic Regression thể hiện hiệu năng khá ấn tượng:\n",
    "* **Ưu điểm:** Đạt **Recall cao nhất (0.7392)** trong cả ba mô hình. Điều này đồng nghĩa với việc mô hình rất giỏi trong việc \"vơ vét\", ít bỏ sót các ứng viên thực sự muốn đổi việc.\n",
    "* **Nhược điểm:** **Precision còn thấp (0.5267)**, tức là mô hình dự báo nhầm khá nhiều người ở lại thành người đi (False Positive cao).\n",
    "* **Đánh giá:** Đóng vai trò là một Baseline ổn định với độ chính xác (**Accuracy**) đạt **0.7648**. Tuy nhiên, chỉ số **F1 (0.6151)** cho thấy sự cân bằng giữa Precision và Recall chưa thực sự tối ưu.\n",
    "\n",
    "#### 2. Random Forest (Sự đánh đổi về Precision)\n",
    "Random Forest mang lại một cách tiếp cận khác biệt so với Logistic Regression:\n",
    "* **Cải thiện:** Tăng được **Precision lên 0.5555**, giúp giảm bớt số lượng cảnh báo giả (\"đỡ đoán nhầm\" hơn).\n",
    "* **Sụt giảm:** Đổi lại, **Recall giảm xuống còn 0.6786**, dẫn đến việc bỏ sót nhiều trường hợp rủi ro hơn.\n",
    "* **Đánh giá:** Với **F1 đạt 0.6109** (thấp hơn cả Logistic), RF cho thấy khả năng cân bằng kém hơn trong bài toán này. Nguyên nhân có thể do hạn chế của RF khi xử lý dữ liệu thưa (One-hot encoding nhiều chiều) và giới hạn về độ sâu của cây.\n",
    "\n",
    "#### 3. XGBoost (The best model - Sự cân bằng hoàn hảo) \n",
    "XGBoost khẳng định vị thế vượt trội trên mọi phương diện quan trọng:\n",
    "* **Hiệu suất:** Đạt **Precision cao nhất (0.5635)** và **Accuracy cao nhất (0.7873)**.\n",
    "* **Khả năng bao quát:** Giữ được **Recall rất cao (0.7238)**, tiệm cận sát nút với Logistic Regression.\n",
    "* **Điểm quyết định:** Chỉ số **F1 đạt 0.6337** (cao nhất trong 3 mô hình).\n",
    "* **Đánh giá:** XGBoost là mô hình tốt nhất vì nó giải quyết được bài toán đánh đổi: vừa bắt được đúng người tìm việc (High Recall), vừa giảm thiểu báo động giả (High Precision).\n",
    "\n",
    "#### 4. Nghịch lý Mô hình (Model Paradox)\n",
    "**1. Tại sao Random Forest (Phi tuyến) thua Logistic Regression (Tuyến tính)?**\n",
    "\n",
    "Mặc dù dữ liệu có tính phi tuyến, Random Forest (RF) hoạt động kém hiệu quả do:\n",
    "* **Vấn đề One-Hot Encoding:** RF gặp khó khăn khi phân chia trên ma trận thưa (nhiều cột 0/1), dẫn đến việc các cây con bị yếu đi do chọn phải đặc trưng kém quan trọng.\n",
    "* **Feature Engineering hiệu quả:** Việc chúng ta tạo sẵn các biến tương tác (như `brain_drain_risk`) và làm sạch dữ liệu kỹ lưỡng đã giúp Logistic Regression dễ dàng tiếp cận các mối quan hệ phức tạp dưới dạng tuyến tính hóa, tận dụng tối đa khả năng tối ưu trọng số toàn cục của nó.\n",
    "\n",
    "**2. Tại sao XGBoost chiến thắng tuyệt đối (dù cùng họ cây với RF)?**\n",
    "\n",
    "XGBoost vượt trội nhờ cơ chế **Gradient Boosting**:\n",
    "* **Học từ lỗi sai:** Thay vì bỏ phiếu ngang hàng như RF, XGBoost xây cây tuần tự để khắc phục lỗi của các cây trước đó, giúp nó bắt được các mẫu dữ liệu khó (hard cases) mà RF bỏ qua.\n",
    "* **Tối ưu hóa trực tiếp:** XGBoost tối ưu hóa hàm mất mát (Log-Loss) tương tự Logistic Regression nhưng trên không gian phi tuyến, kết hợp sức mạnh của cả hai thế giới.\n",
    "* **Sparsity Aware:** XGBoost xử lý dữ liệu One-Hot Encoding hiệu quả hơn hẳn thuật toán chia nút truyền thống của Random Forest.\n",
    "\n",
    "#### **Kết luận chung**\n",
    "Trong ba mô hình, **XGBoost** là lựa chọn tối ưu nhất nhờ khả năng cân bằng xuất sắc giữa Precision và Recall. Kết quả này phản ánh đúng đặc tính của dữ liệu dạng bảng (Structured/Tabular Data), nơi các thuật toán Gradient Boosting như XGBoost thường xuyên chiếm ưu thế so với các phương pháp truyền thống.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw-02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
